# PocketNarrator: Efficient Story Generation with Small Language Models

**Status:** Active Development ðŸš€

PocketNarrator is a research project for the "Efficient Methods in Machine Learning" course (Master Project, WS25/26) at the University of Hamburg. It focuses on building and evaluating small language models for narrative generation using the [TinyStories dataset](https://huggingface.co/datasets/roneneldan/TinyStories).

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Supported Models](#supported-models)
- [Directory Structure](#directory-structure)
- [Requirements](#requirements)
- [Installation](#installation)
  - [1. Clone the Repository](#1-clone-the-repository)
  - [2. Set Up Environment](#2-set-up-environment)
  - [3. Install Python Dependencies](#3-install-python-dependencies)
- [Usage](#usage)
  - [Training](#training)
  - [Evaluation](#evaluation)
  - [Generation](#generation)
- [Project Structure](#project-structure)
- [Team](#team)

## Overview

PocketNarrator is a systematic investigation into the architecture and components of small language models for efficient narrative generation. Our goal is to understand trade-offs between different architectural choices in terms of performance, computational efficiency, and output quality.

The project implements multiple model architectures from scratch using PyTorch, trained on the [TinyStories dataset](https://huggingface.co/datasets/roneneldan/TinyStories)â€”a clean, restricted-domain collection of children's stories ideal for training efficient models. Our models are designed for next-token prediction and story continuation tasks.

## Features

- **Multiple model architectures** supporting N-gram and Transformer models
- **Comprehensive evaluation metrics** including BLEU, ROUGE, perplexity, distinct-n, text quality, and noun carryover analysis
- **Flexible tokenization** with BPE and character-level tokenizers
- **W&B integration** for experiment tracking and visualization
- **Production-ready evaluation pipeline** with model comparison and dataset analysis tools
- **Clean, modular codebase** with abstract base classes for extensibility

## Supported Models

- **N-gram Model**: Lightweight baseline model for quick experiments
- **Transformer Model**: Custom decoder-only transformer architecture with configurable attention mechanisms

## Directory Structure

```
pocket-narrator/
â”œâ”€â”€ README.md                            # Project documentation
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ pyproject.toml                       # Project configuration
â”œâ”€â”€ pytest.ini                           # Pytest configuration
â”‚
â”œâ”€â”€ configs/                             # Configuration files for models and training
â”‚   â”œâ”€â”€ base_config.yaml
â”‚   â”œâ”€â”€ evaluation/                      # Evaluation configs
â”‚   â”œâ”€â”€ models/                          # Model-specific configs
â”‚   â”œâ”€â”€ tokenizers/                      # Tokenizer configs
â”‚   â””â”€â”€ training/                        # Training configs
â”‚
â”œâ”€â”€ data/                                # Datasets (raw and processed)
â”‚   â”œâ”€â”€ raw/                             # Original dataset files
â”‚   â””â”€â”€ processed/                       # Processed datasets
â”‚
â”œâ”€â”€ models/                              # Trained model checkpoints
â”‚   â”œâ”€â”€ ngram/
â”‚   â”œâ”€â”€ transformer/
â”‚   â””â”€â”€ cool_models/
â”‚
â”œâ”€â”€ notebooks/                           # Jupyter notebooks for exploration
â”‚
â”œâ”€â”€ pocket_narrator/                     # Main package source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/                          # Model architectures
â”‚   â”‚   â”œâ”€â”€ base_model.py                # Abstract base class
â”‚   â”‚   â”œâ”€â”€ ngram_model.py               # N-gram implementation
â”‚   â”‚   â”œâ”€â”€ components/                  # Reusable components
â”‚   â”‚   â”‚   â”œâ”€â”€ positional_encoding.py
â”‚   â”‚   â”‚   â””â”€â”€ base_pos_encoding.py
â”‚   â”‚   â””â”€â”€ transformers/                # Transformer architecture
â”‚   â”‚       â”œâ”€â”€ model.py
â”‚   â”‚       â”œâ”€â”€ transformer_block.py
â”‚   â”‚       â”œâ”€â”€ attention.py
â”‚   â”‚       â””â”€â”€ base_attention.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tokenizers/                      # Tokenization implementations
â”‚   â”‚   â”œâ”€â”€ base_tokenizer.py
â”‚   â”‚   â”œâ”€â”€ bpe_tokenizer.py
â”‚   â”‚   â””â”€â”€ character_tokenizer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ trainers/                        # Model trainers
â”‚   â”‚   â”œâ”€â”€ base_trainer.py
â”‚   â”‚   â”œâ”€â”€ ngram_trainer.py
â”‚   â”‚   â””â”€â”€ transformer_trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_loader.py                   # Data loading utilities
â”‚   â”œâ”€â”€ evaluate.py                      # Evaluation metrics
â”‚   â”œâ”€â”€ text_quality.py                  # Text quality evaluation
â”‚   â”œâ”€â”€ noun_carryover.py                # Noun carryover metrics
â”‚   â””â”€â”€ gemini_api.py                    # LLM-based evaluation
â”‚
â”œâ”€â”€ scripts/                             # Standalone execution scripts
â”‚   â”œâ”€â”€ train.py                         # Main training script
â”‚   â”œâ”€â”€ generate.py                      # Text generation
â”‚   â”œâ”€â”€ evaluate_model.py                # Single model evaluation
â”‚   â”œâ”€â”€ evaluate_dataset_comprehensive.py # Dataset evaluation
â”‚   â”œâ”€â”€ preprocess.py                    # Data preprocessing
â”‚   â”œâ”€â”€ fetch_tinystories.py             # Dataset download
â”‚   â””â”€â”€ â€¦
â”‚
â”œâ”€â”€ tests/                               # Unit and integration tests
â”‚
â”œâ”€â”€ tokenizers/                          # Saved tokenizer artifacts
â”‚
â”œâ”€â”€ results/                             # Evaluation results (JSON)
â”‚
â””â”€â”€ wandb/                               # W&B experiment tracking
```

## Requirements

- Python 3.8+
- PyTorch 2.0+
- NumPy, Pandas
- Hugging Face Transformers & Datasets
- wandb (for experiment tracking)
- Optional: spacy, sentence-transformers, google-genai (for advanced evaluation)

## Installation

### 1. Clone the Repository

```bash
git clone https://github.com/bschink/pocket-narrator.git
cd pocket-narrator
```

### 2. Set Up Environment

```bash
# Create conda environment with PyTorch
conda create -n pocket-narrator python=3.10 pytorch pytorch-cuda=12.1 -c pytorch -c nvidia

# Activate the conda environment
conda activate pocket-narrator
```

### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

## Usage

### Training

Train a model using the training script:

```bash
# Train with default config
python scripts/train.py

# Train with specific config
python scripts/train.py --config_path configs/training/train_tinystories_1M.yaml

# Key arguments:
#   --config_path: Path to training config YAML
#   --model_type: ngram or transformer
#   --dataset_path: Path to dataset
#   --output_dir: Directory to save models
#   --epochs: Number of training epochs
#   --batch_size: Batch size for training
```

### Evaluation

Evaluate a trained model on a dataset:

```bash
# Evaluate single model with comprehensive metrics
python scripts/evaluate_model.py \
    --model_path models/transformer/transformer_model.pth \
    --model_type transformer \
    --dataset_path data/test_dataset.txt

# Evaluate dataset without a model (text quality, distinct-n, etc.)
python scripts/evaluate_dataset_comprehensive.py \
    --dataset_path data/validation.txt \
    --dataset_name "TinyStories Validation"
```

### Generation

Generate text continuations with a trained model:

```bash
# Generate with default prompt
python scripts/generate.py \
    --model_path models/transformer/transformer_model.pth \
    --model_type transformer

# Generate with custom prompt
python scripts/generate.py \
    --model_path models/transformer/transformer_model.pth \
    --model_type transformer \
    --prompt "A girl went to the" \
    --max_length 100 \
    --temperature 0.7
```

## Project Structure

### Core Components

- **Models**: Extensible model implementations (N-gram, Transformer)
- **Tokenizers**: Multiple tokenization strategies (BPE, character-level)
- **Trainers**: Trainer classes for different architectures
- **Evaluation**: Comprehensive metrics (BLEU, ROUGE, perplexity, text quality, LLM judgments)

### Key Features

- **Configuration-driven**: All experiments defined in YAML configs
- **Experiment tracking**: W&B integration for logging and visualization
- **Modular design**: Easy to add new models, tokenizers, or evaluation metrics
- **Well-tested**: Unit and integration tests for core functionality

## Team

Asiya Yumna, Kosar Hazrati & Benedikt Schink
