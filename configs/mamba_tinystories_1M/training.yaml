name: mamba_tinystories_1M_train
output_dir: results/mamba_tinystories_1M
batch_size: 8  # 8 -->16-->32--->64
learning_rate: 3.0e-4
weight_decay: 0.1
num_train_epochs: 4

grad_accum_steps: 1
max_grad_norm: 1.0
num_workers: 0 # On macOS, set num_workers: 0 first to stop spawn worker crashes while debugging.
#at the first was 4 ---> we had problem for training


# for quick test training
#num_train_epochs: 1
#batch_size: 16

log_samples_every_n_epochs: 1
sample_max_new_tokens: 64
sample_temperature: 0.8
sample_top_k: 50
sample_prompts:
  - "Once upon a time"
  - "The robot said"


