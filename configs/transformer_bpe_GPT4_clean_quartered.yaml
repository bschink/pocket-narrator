run_name: "transformer_bpe_GPT4_clean_quartered"

data:
  path: "data/processed/TinyStories/TinyStoriesV2-GPT4-train.clean.quarted.txt"
  val_ratio: 0.2
  random_seed: 42
  batch_size: 2

tokenizer:
  type: "bpe"
  path: "tokenizers/bpe_tokenizer"
  tokenizer_config:
    vocab_size: 10000
    merges_per_round: 200
    special_tokens: ["<|endoftext|>"]

model:
  type: "transformer"
  # using TransformerModel.from_config defaults for now

trainer:
  type: "transformer"
  # using TransformerTrainer defaults

generation:
  strategy: "greedy"
  no_repeat_ngram_size: 3

saving:
  model_dir: "models/transformer"
  model_name: null
